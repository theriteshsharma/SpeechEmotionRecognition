{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332759bc-db52-4c5a-9b54-3239f6f749e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import pickle\n",
    "\n",
    "#imports for cnn\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c95307-76c0-450e-98ad-8649e957b0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec6b7e-48aa-4238-ba00-9ccf55d28c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019e9abf-7463-404f-a532-0ec19a6c0d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48ce313-7332-49a1-b443-54ba7c79a3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdda6fa5-1138-4da0-ad53-de08965e0205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.04*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.70):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.8):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "def higher_speed(data, speed_factor = 1.25):\n",
    "    return librosa.effects.time_stretch(data, speed_factor)\n",
    "\n",
    "def lower_speed(data, speed_factor = 0.75):\n",
    "    return librosa.effects.time_stretch(data, speed_factor)\n",
    "def extract_features(data):\n",
    "    \n",
    "    result = np.array([])\n",
    "    \n",
    "    #mfccs = librosa.feature.mfcc(y=data, sr=22050, n_mfcc=42) #42 mfcc so we get frames of ~60 ms\n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=22050, n_mfcc=58)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "    result = np.array(mfccs_processed)\n",
    "     \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=3, offset=0.5, res_type='kaiser_fast') \n",
    "    \n",
    "    #without augmentation\n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    #noised\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "    \n",
    "    #stretched\n",
    "    stretch_data = stretch(data)\n",
    "    res3 = extract_features(stretch_data)\n",
    "    result = np.vstack((result, res3))\n",
    "    \n",
    "    #shifted\n",
    "    shift_data = shift(data)\n",
    "    res4 = extract_features(shift_data)\n",
    "    result = np.vstack((result, res4))\n",
    "    \n",
    "    #pitched\n",
    "    pitch_data = pitch(data, sample_rate)\n",
    "    res5 = extract_features(pitch_data)\n",
    "    result = np.vstack((result, res5)) \n",
    "    \n",
    "    #speed up\n",
    "    higher_speed_data = higher_speed(data)\n",
    "    res6 = extract_features(higher_speed_data)\n",
    "    result = np.vstack((result, res6))\n",
    "    \n",
    "    #speed down\n",
    "    lower_speed_data = higher_speed(data)\n",
    "    res7 = extract_features(lower_speed_data)\n",
    "    result = np.vstack((result, res7))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e93b8f1-0815-42d1-bdeb-742ca2a6486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = pd.read_csv(\"males_emotions_df.csv\")\n",
    "female = pd.read_csv(\"females_emotions_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f6f2a9-1613-4b43-86a4-e8396914388f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767004f-76fc-479b-95fd-6cfdce6a6e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ser",
   "language": "python",
   "name": "ser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
